{"cells": [{"metadata": {"id": "3a84dd0791f54f2eba25d609d4f4f322"}, "cell_type": "markdown", "source": "# Install OpenVINO in IBM Cloud Pak for Data - Watson Studio Jupyter Env"}, {"metadata": {"id": "7450cea6960b437f8309beea421ddf4b"}, "cell_type": "markdown", "source": "### Use Python 3.6 in IBM CP4D Watson Studio Jupyter Env\n### OpenVINO currently supports Python 3.6, 3.8 on Red Hat* Enterprise Linux* 8, 64-bit\t\n"}, {"metadata": {"id": "26cce525dbbb4c05883ec830764ee424"}, "cell_type": "markdown", "source": "### Sections in the notebook:\n1. Install OpenVINO\n2. Test OpenVINO python imports\n3. Test OpenVINO tools: Model Optimizer, Benchmark App\n4. Sanity check OpenVINO by donwloading, converting and benchmarking googlenet-v1-tf model"}, {"metadata": {"id": "f654368fde164285a10ef2c79811d8cb"}, "cell_type": "markdown", "source": "### Resources:\n1. OpenVINO PyPi: https://pypi.org/project/openvino-dev/\n2. IBM CP4D: [Customizing environment definitions (Watson Studio)](https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_latest/wsj/analyze-data/cust-env-parent.html)"}, {"metadata": {"id": "0e9acd13bd3d48cd9d6064a4abd30bb8"}, "cell_type": "markdown", "source": "## 1. Install OpenVINO"}, {"metadata": {"id": "7aff8282-127b-43aa-8738-c0096a11e805"}, "cell_type": "code", "source": "# Install this specific version of OpenCV to prevent libGl errors\n!pip uninstall -y opencv-python\n!pip install -U opencv-python-headless==4.2.0.32 --user", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\nCollecting opencv-python-headless==4.2.0.32\n  Downloading opencv_python_headless-4.2.0.32-cp36-cp36m-manylinux1_x86_64.whl (21.6 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21.6 MB 13.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.3 in /opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages (from opencv-python-headless==4.2.0.32) (1.16.6)\nInstalling collected packages: opencv-python-headless\nSuccessfully installed opencv-python-headless-4.2.0.32\n", "name": "stdout"}]}, {"metadata": {"id": "ef47c5b9189a4e9a9207d4d88861ce89"}, "cell_type": "code", "source": "# Install OpenVINO\n!pip install --ignore-installed PyYAML openvino-dev", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Collecting PyYAML\n  Downloading PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 640 kB 20.2 MB/s eta 0:00:01\n\u001b[?25hCollecting openvino-dev\n  Downloading openvino_dev-2021.4.0-3839-py3-none-any.whl (6.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.2 MB 38.0 MB/s eta 0:00:01\n\u001b[?25hCollecting opencv-python==4.5.*\n  Downloading opencv_python-4.5.3.56-cp36-cp36m-manylinux2014_x86_64.whl (49.9 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 49.9 MB 51.7 MB/s eta 0:00:01\n\u001b[?25hCollecting defusedxml>=0.7.1\n  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\nCollecting sentencepiece>=0.1.95\n  Downloading sentencepiece-0.1.96-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.2 MB 41.4 MB/s eta 0:00:01\n\u001b[?25hCollecting hyperopt~=0.1.2\n  Downloading hyperopt-0.1.2-py3-none-any.whl (115 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 115 kB 43.2 MB/s eta 0:00:01\n\u001b[?25hCollecting jstyleson~=0.0.2\n  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\nCollecting fast-ctc-decode>=0.2.5\n  Downloading fast_ctc_decode-0.3.0-cp36-cp36m-manylinux2010_x86_64.manylinux1_x86_64.whl (508 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 508 kB 46.4 MB/s eta 0:00:01\n\u001b[?25hCollecting tqdm>=4.54.1\n  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 76 kB 9.9 MB/s  eta 0:00:01\n\u001b[?25hCollecting networkx~=2.5\n  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.6 MB 44.6 MB/s eta 0:00:01\n\u001b[?25hCollecting shapely>=1.7.1\n  Downloading Shapely-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.0 MB 31.7 MB/s eta 0:00:01\n\u001b[?25hCollecting rawpy>=0.16.0\n  Downloading rawpy-0.16.0-cp36-cp36m-manylinux2010_x86_64.whl (1.7 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.7 MB 39.1 MB/s eta 0:00:01\n\u001b[?25hCollecting numpy<1.20,>=1.16.6\n  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.8 MB 37.2 MB/s eta 0:00:01\u2588\u258b                   | 5.9 MB 37.2 MB/s eta 0:00:01\n\u001b[?25hCollecting texttable~=1.6.3\n  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\nCollecting openvino==2021.4.0\n  Downloading openvino-2021.4.0-3839-cp36-cp36m-manylinux2014_x86_64.whl (28.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28.2 MB 18.8 MB/s eta 0:00:01   |                                | 71 kB 17.1 MB/s eta 0:00:02     |\u2588\u258c                              | 1.3 MB 18.8 MB/s eta 0:00:02     |\u2588\u2588\u2588\u2588\u2588\u258a                          | 5.1 MB 18.8 MB/s eta 0:00:02\n\u001b[?25hCollecting yamlloader>=0.5\n  Downloading yamlloader-1.1.0-py3-none-any.whl (6.6 kB)\nCollecting nibabel>=3.2.1\n  Downloading nibabel-3.2.1-py3-none-any.whl (3.3 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.3 MB 46.6 MB/s eta 0:00:01\u2588\u2588\u2588\u258c                    | 1.2 MB 46.6 MB/s eta 0:00:01\n\u001b[?25hCollecting py-cpuinfo>=7.0.0\n  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 99 kB 14.9 MB/s eta 0:00:01\n\u001b[?25hCollecting scikit-image~=0.17.2\n  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.4 MB 12.1 MB/s eta 0:00:01\n\u001b[?25hCollecting scikit-learn>=0.24.1\n  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22.2 MB 4.0 MB/s eta 0:00:01\n\u001b[?25hCollecting pandas~=1.1.5\n  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.5 MB 12.9 MB/s eta 0:00:01     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c             | 5.5 MB 12.9 MB/s eta 0:00:01\n\u001b[?25hCollecting tokenizers>=0.10.1\n  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.3 MB 44.3 MB/s eta 0:00:01\n\u001b[?25hCollecting pillow>=8.1.2\n  Downloading Pillow-8.3.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.0 MB 41.9 MB/s eta 0:00:01\n\u001b[?25hCollecting editdistance>=0.5.3\n  Downloading editdistance-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (178 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 178 kB 44.4 MB/s eta 0:00:01\n\u001b[?25hCollecting addict>=2.4.0\n  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nCollecting requests>=2.25.1\n  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 62 kB 2.0 MB/s  eta 0:00:01\n\u001b[?25hCollecting nltk>=3.5\n  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.5 MB 36.3 MB/s eta 0:00:01\n\u001b[?25hCollecting progress>=1.5\n  Downloading progress-1.5.tar.gz (5.8 kB)\nCollecting pydicom>=2.1.2\n  Downloading pydicom-2.1.2-py3-none-any.whl (1.9 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.9 MB 38.8 MB/s eta 0:00:01\n\u001b[?25hCollecting scipy~=1.5.4\n  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25.9 MB 4.9 MB/s eta 0:00:01\n\u001b[?25hCollecting parasail>=1.2.4\n  Downloading parasail-1.2.4-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 14.1 MB 9.7 MB/s eta 0:00:01\n\u001b[?25hCollecting pymongo\n  Downloading pymongo-3.12.0-cp36-cp36m-manylinux2014_x86_64.whl (523 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 523 kB 21.1 MB/s eta 0:00:01     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                     | 174 kB 21.1 MB/s eta 0:00:01\n\u001b[?25hCollecting future\n  Downloading future-0.18.2.tar.gz (829 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 829 kB 36.7 MB/s eta 0:00:01\n\u001b[?25hCollecting six\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nCollecting decorator<5,>=4.3\n  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nCollecting packaging>=14.3\n  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40 kB 11.2 MB/s eta 0:00:01\n\u001b[?25hCollecting imageio>=2.3.0\n  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.3 MB 11.2 MB/s eta 0:00:01\n\u001b[?25hCollecting PyWavelets>=1.1.1\n  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.4 MB 38.1 MB/s eta 0:00:01\n\u001b[?25hCollecting tifffile>=2019.7.26\n  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 148 kB 37.7 MB/s eta 0:00:01\n\u001b[?25hCollecting matplotlib!=3.0.0,>=2.0.0\n  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11.5 MB 6.7 MB/s eta 0:00:01\n\u001b[?25hCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\nCollecting joblib>=0.11\n  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 303 kB 44.7 MB/s eta 0:00:01\n\u001b[?25hCollecting python-dateutil>=2.7.3\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 247 kB 45.4 MB/s eta 0:00:01\n\u001b[?25hCollecting pytz>=2017.2\n  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 510 kB 44.3 MB/s eta 0:00:01\n\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 138 kB 42.9 MB/s eta 0:00:01\n\u001b[?25hCollecting charset-normalizer~=2.0.0; python_version >= \"3\"\n  Downloading charset_normalizer-2.0.1-py3-none-any.whl (35 kB)\nCollecting certifi>=2017.4.17\n  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 145 kB 38.6 MB/s eta 0:00:01\n\u001b[?25hCollecting idna<4,>=2.5; python_version >= \"3\"\n  Downloading idna-3.2-py3-none-any.whl (59 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 59 kB 13.2 MB/s eta 0:00:01\n\u001b[?25hCollecting click\n  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 97 kB 12.5 MB/s eta 0:00:01\n\u001b[?25hCollecting regex\n  Downloading regex-2021.7.6-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 722 kB 40.5 MB/s eta 0:00:01\n", "name": "stdout"}, {"output_type": "stream", "text": "\u001b[?25hCollecting pyparsing>=2.0.2\n  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 67 kB 11.4 MB/s eta 0:00:01\n\u001b[?25hCollecting cycler>=0.10\n  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\nCollecting kiwisolver>=1.0.1\n  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.1 MB 41.0 MB/s eta 0:00:01\n\u001b[?25hCollecting importlib-metadata; python_version < \"3.8\"\n  Downloading importlib_metadata-4.6.1-py3-none-any.whl (17 kB)\nCollecting typing-extensions>=3.6.4; python_version < \"3.8\"\n  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.5.0-py3-none-any.whl (5.7 kB)\nBuilding wheels for collected packages: jstyleson, py-cpuinfo, progress, future\n  Building wheel for jstyleson (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2401 sha256=3cfee5a61276fe571495ff879e739c3fd0ed0d66249ad5533da83e2ad444e843\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/b4/81/d5/cdb314e9ce581447d273295dae3047b4ce87573996df43c0cd\n  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22245 sha256=955b732e2878280bb085660faa1f70706f0e71c370df408774f18c4d8bbe6dd8\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/3e/e1/d9/9b782b170e5272d6500cee4d29dd6c724598b22dc399d81d01\n  Building wheel for progress (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for progress: filename=progress-1.5-py3-none-any.whl size=8074 sha256=215f5ac6c7ac5ba827d4ea1fb8c9ff9b005d4cd0d60de915d6b1406090c1bbb4\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/e5/d6/71/e87d26b0205f2c12e55a1a554214668ee324a962bad857c56a\n  Building wheel for future (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=f59c5109812cc530373a157a821df47b11314a3326309236465d47f151f2eb70\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\nSuccessfully built jstyleson py-cpuinfo progress future\n\u001b[31mERROR: tensorflow 1.15.2 requires opt-einsum>=2.3.2, which is not installed.\u001b[0m\n\u001b[31mERROR: hdijupyterutils 0.12.9 requires jupyter>=1, which is not installed.\u001b[0m\n\u001b[31mERROR: brunel 2.3 requires JPype1-py3, which is not installed.\u001b[0m\n\u001b[31mERROR: ibm-watson-machine-learning 1.0.45 has requirement pandas<=1.0.5, but you'll have pandas 1.1.5 which is incompatible.\u001b[0m\n\u001b[31mERROR: botocore 1.12.82 has requirement urllib3<1.25,>=1.20, but you'll have urllib3 1.26.6 which is incompatible.\u001b[0m\nInstalling collected packages: PyYAML, numpy, opencv-python, defusedxml, sentencepiece, decorator, networkx, scipy, pymongo, future, six, tqdm, hyperopt, jstyleson, fast-ctc-decode, shapely, rawpy, texttable, openvino, yamlloader, pyparsing, packaging, nibabel, py-cpuinfo, pillow, imageio, PyWavelets, tifffile, cycler, kiwisolver, python-dateutil, matplotlib, scikit-image, threadpoolctl, joblib, scikit-learn, pytz, pandas, tokenizers, editdistance, addict, urllib3, charset-normalizer, certifi, idna, requests, typing-extensions, zipp, importlib-metadata, click, regex, nltk, progress, pydicom, parasail, openvino-dev\nSuccessfully installed PyWavelets-1.1.1 PyYAML-5.4.1 addict-2.4.0 certifi-2021.5.30 charset-normalizer-2.0.1 click-8.0.1 cycler-0.10.0 decorator-4.4.2 defusedxml-0.7.1 editdistance-0.5.3 fast-ctc-decode-0.3.0 future-0.18.2 hyperopt-0.1.2 idna-3.2 imageio-2.9.0 importlib-metadata-4.6.1 joblib-1.0.1 jstyleson-0.0.2 kiwisolver-1.3.1 matplotlib-3.3.4 networkx-2.5.1 nibabel-3.2.1 nltk-3.6.2 numpy-1.19.5 opencv-python-4.5.3.56 openvino-2021.4.0 openvino-dev-2021.4.0 packaging-21.0 pandas-1.1.5 parasail-1.2.4 pillow-8.3.1 progress-1.5 py-cpuinfo-8.0.0 pydicom-2.1.2 pymongo-3.12.0 pyparsing-2.4.7 python-dateutil-2.8.2 pytz-2021.1 rawpy-0.16.0 regex-2021.7.6 requests-2.26.0 scikit-image-0.17.2 scikit-learn-0.24.2 scipy-1.5.4 sentencepiece-0.1.96 shapely-1.7.1 six-1.16.0 texttable-1.6.4 threadpoolctl-2.2.0 tifffile-2020.9.3 tokenizers-0.10.3 tqdm-4.61.2 typing-extensions-3.10.0.0 urllib3-1.26.6 yamlloader-1.1.0 zipp-3.5.0\n", "name": "stdout"}]}, {"metadata": {"id": "8f19bcb3f1954e1c80746c937f1329fc", "scrolled": true}, "cell_type": "code", "source": "!pip show openvino", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Name: openvino\r\nVersion: 2021.4.0\r\nSummary: Inference Engine Python* API\r\nHome-page: https://docs.openvinotoolkit.org/latest/index.html\r\nAuthor: Intel Corporation\r\nAuthor-email: openvino_pushbot@intel.com\r\nLicense: Proprietary - Intel\r\nLocation: /opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages\r\nRequires: numpy\r\nRequired-by: openvino-dev\r\n", "name": "stdout"}]}, {"metadata": {"id": "05d697550317482189bbcdd29477ecb2"}, "cell_type": "markdown", "source": "### After installing, Restart Kernel just to be sure..."}, {"metadata": {"id": "0bdb111a86d24c9885985ba7d91268d6"}, "cell_type": "markdown", "source": "## 2. Test OpenVINO python imports"}, {"metadata": {"id": "f5ebc3e9eadc40ca8716d1dacc6489c3"}, "cell_type": "code", "source": "from openvino.inference_engine import IENetwork, IECore\nfrom openvino.tools.benchmark.main import main", "execution_count": 7, "outputs": []}, {"metadata": {"id": "aa8d6023fabf490683bf4d75e0c9e74e"}, "cell_type": "markdown", "source": "## 3. Test OpenVINO tools: Model Optimizer, Benchmark App, ..."}, {"metadata": {"id": "cf04e2e81b1049e383b0bb62db50fb79"}, "cell_type": "markdown", "source": "### Test Model Optimizer"}, {"metadata": {"id": "615ca08063454ee59d5d3a0afacf6ac7"}, "cell_type": "code", "source": "!mo --version", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "Version of Model Optimizer is: 2021.4.0-3839-cd81789d294-releases/2021/4\r\n", "name": "stdout"}]}, {"metadata": {"id": "71fd9d4272f840d3b41c5c90d20ad4b1"}, "cell_type": "markdown", "source": "### Test Benchmark App"}, {"metadata": {"id": "681bb6c8b36e40b68b05311697cb3d1f"}, "cell_type": "code", "source": "!benchmark_app ", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "[Step 1/11] Parsing and validating input arguments\r\nusage: benchmark_app [-h [HELP]] [-i PATHS_TO_INPUT [PATHS_TO_INPUT ...]] -m\r\n                     PATH_TO_MODEL [-d TARGET_DEVICE] [-l PATH_TO_EXTENSION]\r\n                     [-c PATH_TO_CLDNN_CONFIG] [-api {sync,async}]\r\n                     [-niter NUMBER_ITERATIONS] [-nireq NUMBER_INFER_REQUESTS]\r\n                     [-b BATCH_SIZE] [-stream_output [STREAM_OUTPUT]]\r\n                     [-t TIME] [-progress [PROGRESS]] [-shape SHAPE]\r\n                     [-layout LAYOUT] [-nstreams NUMBER_STREAMS]\r\n                     [-enforcebf16 [{True,False}]] [-nthreads NUMBER_THREADS]\r\n                     [-pin {YES,NO,NUMA,HYBRID_AWARE}]\r\n                     [-exec_graph_path EXEC_GRAPH_PATH] [-pc [PERF_COUNTS]]\r\n                     [-report_type {no_counters,average_counters,detailed_counters}]\r\n                     [-report_folder REPORT_FOLDER] [-dump_config DUMP_CONFIG]\r\n                     [-load_config LOAD_CONFIG] [-qb {8,16}]\r\n                     [-ip {U8,FP16,FP32}] [-op {U8,FP16,FP32}]\r\n                     [-iop INPUT_OUTPUT_PRECISION] [-cdir CACHE_DIR]\r\n                     [-lfile [LOAD_FROM_FILE]]\r\nbenchmark_app: error: the following arguments are required: -m/--path_to_model\r\n", "name": "stdout"}]}, {"metadata": {"id": "aea7148993b54701844377a75ef2af66"}, "cell_type": "markdown", "source": "### See other tools:"}, {"metadata": {"id": "4c62e4c8a0d84964ba3aaae8ea9fccc3"}, "cell_type": "code", "source": "!ls /opt/conda/envs/Python-3.6-WMLCE/bin/omz*", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "/opt/conda/envs/Python-3.6-WMLCE/bin/omz_converter\r\n/opt/conda/envs/Python-3.6-WMLCE/bin/omz_downloader\r\n/opt/conda/envs/Python-3.6-WMLCE/bin/omz_info_dumper\r\n/opt/conda/envs/Python-3.6-WMLCE/bin/omz_quantizer\r\n", "name": "stdout"}]}, {"metadata": {"id": "911bad7f35bb40978017463432b088f8"}, "cell_type": "markdown", "source": "## 4. Sanity check OpenVINO by donwloading, converting and benchmarking googlenet-v1-tf model\n"}, {"metadata": {"id": "3015d3c1b6da4e4ba6e1084701a2108b"}, "cell_type": "markdown", "source": "### Resources:\n\n1. OpenVINO Model Zoo (OMZ): https://github.com/openvinotoolkit/open_model_zoo\n1. OMZ Intel Pre-Trained Models : https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/index.md\n1. OMZ Public Pre-Trained Models: See Column 3 for OMZ model name: https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/index.md"}, {"metadata": {"id": "f8c88985ca16414082ec60115a4f754a"}, "cell_type": "markdown", "source": "### Download  `googlenet-v1-tf` model from OMZ"}, {"metadata": {"id": "bb14aaa7793b413383142b1bc383e91c", "scrolled": true}, "cell_type": "code", "source": "!omz_downloader --name googlenet-v1-tf", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "################|| Downloading googlenet-v1-tf ||################\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/inception_v1_2016_08_28.tar.gz\n... 100%, 24064 KB, 65398 KB/s, 0 seconds passed399 KB/s, 0 seconds passed seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/inception.py\n... 100%, 1 KB, 4561 KB/s, 0 seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/inception_utils.py\n... 100%, 3 KB, 11353 KB/s, 0 seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/inception_v1.py\n... 100%, 16 KB, 45890 KB/s, 0 seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/nets_factory.py\n... 100%, 7 KB, 24585 KB/s, 0 seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/tf_slim-1.1.0-py2.py3-none-any.whl\n... 100%, 343 KB, 32917 KB/s, 0 seconds passed\n\n========== Unpacking /home/wsuser/work/public/googlenet-v1-tf/inception_v1_2016_08_28.tar.gz\n========== Unpacking /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/tf_slim-1.1.0-py2.py3-none-any.whl\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/nets_factory.py\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/nets_factory.py\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/inception.py\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/nets_factory.py\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/tf_slim/layers/layers.py\n\n", "name": "stdout"}]}, {"metadata": {"id": "0f9c1cb31a874f8db5d37b550d5b45d3"}, "cell_type": "code", "source": "!ls public/googlenet-v1-tf/", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "FP16  FP32  inception_v1.ckpt  inception_v1.frozen.pb  models\r\n", "name": "stdout"}]}, {"metadata": {"id": "97f8ea53e843446c83f45c797a04c50f"}, "cell_type": "markdown", "source": "### Convert `googlenet-v1-tf` model to OpenVINO IR"}, {"metadata": {"id": "fe5f01a0bdd147e087f26ed5f9858755"}, "cell_type": "code", "source": "!omz_converter --name googlenet-v1-tf", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "========== Running pre-convert script for googlenet-v1-tf\nPre-convert command: /opt/conda/envs/Python-3.6-WMLCE/bin/python -- /opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/open_model_zoo/model_tools/models/public/googlenet-v1-tf/pre-convert.py -- /home/wsuser/work/public/googlenet-v1-tf /home/wsuser/work/public/googlenet-v1-tf\n\n2021-07-14 16:06:18.268902: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2021-07-14 16:06:18.279270: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 2100030000 Hz\n2021-07-14 16:06:18.282332: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557b1b9efd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2021-07-14 16:06:18.282441: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\nWARNING: Logging before flag parsing goes to stderr.\nW0714 16:06:21.330549 140485216085824 deprecation.py:323] From /opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/open_model_zoo/model_tools/models/public/googlenet-v1-tf/pre-convert.py:45: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\nW0714 16:06:21.331076 140485216085824 deprecation.py:323] From /opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.extract_sub_graph`\n\n========== Converting googlenet-v1-tf to IR (FP16)\nConversion command: /opt/conda/envs/Python-3.6-WMLCE/bin/python -m mo --framework=tf --data_type=FP16 --output_dir=/home/wsuser/work/public/googlenet-v1-tf/FP16 --model_name=googlenet-v1-tf '--input_shape=[1,224,224,3]' --input=input '--mean_values=input[127.5,127.5,127.5]' '--scale_values=input[127.5]' --output=InceptionV1/Logits/Predictions/Softmax --input_model=/home/wsuser/work/public/googlenet-v1-tf/inception_v1.frozen.pb --reverse_input_channels\n\nModel Optimizer arguments:\nCommon parameters:\n\t- Path to the Input Model: \t/home/wsuser/work/public/googlenet-v1-tf/inception_v1.frozen.pb\n\t- Path for generated IR: \t/home/wsuser/work/public/googlenet-v1-tf/FP16\n\t- IR output name: \tgooglenet-v1-tf\n\t- Log level: \tERROR\n\t- Batch: \tNot specified, inherited from the model\n\t- Input layers: \tinput\n\t- Output layers: \tInceptionV1/Logits/Predictions/Softmax\n\t- Input shapes: \t[1,224,224,3]\n\t- Mean values: \tinput[127.5,127.5,127.5]\n\t- Scale values: \tinput[127.5]\n\t- Scale factor: \tNot specified\n\t- Precision of IR: \tFP16\n\t- Enable fusing: \tTrue\n\t- Enable grouped convolutions fusing: \tTrue\n\t- Move mean values to preprocess section: \tNone\n\t- Reverse input channels: \tTrue\nTensorFlow specific parameters:\n\t- Input model in text protobuf format: \tFalse\n\t- Path to model dump for TensorBoard: \tNone\n\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n\t- Update the configuration file with input/output node names: \tNone\n\t- Use configuration file used to generate the model with Object Detection API: \tNone\n\t- Use the config file: \tNone\n\t- Inference Engine found in: \t/opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/openvino\nInference Engine version: \t2021.4.0-3839-cd81789d294-releases/2021/4\nModel Optimizer version: \t2021.4.0-3839-cd81789d294-releases/2021/4\n/opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  import imp\n[ SUCCESS ] Generated IR version 10 model.\n[ SUCCESS ] XML file: /home/wsuser/work/public/googlenet-v1-tf/FP16/googlenet-v1-tf.xml\n[ SUCCESS ] BIN file: /home/wsuser/work/public/googlenet-v1-tf/FP16/googlenet-v1-tf.bin\n[ SUCCESS ] Total execution time: 36.19 seconds. \n[ SUCCESS ] Memory consumed: 420 MB. \n\n========== Converting googlenet-v1-tf to IR (FP32)\nConversion command: /opt/conda/envs/Python-3.6-WMLCE/bin/python -m mo --framework=tf --data_type=FP32 --output_dir=/home/wsuser/work/public/googlenet-v1-tf/FP32 --model_name=googlenet-v1-tf '--input_shape=[1,224,224,3]' --input=input '--mean_values=input[127.5,127.5,127.5]' '--scale_values=input[127.5]' --output=InceptionV1/Logits/Predictions/Softmax --input_model=/home/wsuser/work/public/googlenet-v1-tf/inception_v1.frozen.pb --reverse_input_channels\n\nModel Optimizer arguments:\nCommon parameters:\n\t- Path to the Input Model: \t/home/wsuser/work/public/googlenet-v1-tf/inception_v1.frozen.pb\n\t- Path for generated IR: \t/home/wsuser/work/public/googlenet-v1-tf/FP32\n\t- IR output name: \tgooglenet-v1-tf\n\t- Log level: \tERROR\n\t- Batch: \tNot specified, inherited from the model\n\t- Input layers: \tinput\n\t- Output layers: \tInceptionV1/Logits/Predictions/Softmax\n\t- Input shapes: \t[1,224,224,3]\n\t- Mean values: \tinput[127.5,127.5,127.5]\n\t- Scale values: \tinput[127.5]\n\t- Scale factor: \tNot specified\n\t- Precision of IR: \tFP32\n\t- Enable fusing: \tTrue\n\t- Enable grouped convolutions fusing: \tTrue\n\t- Move mean values to preprocess section: \tNone\n\t- Reverse input channels: \tTrue\nTensorFlow specific parameters:\n\t- Input model in text protobuf format: \tFalse\n\t- Path to model dump for TensorBoard: \tNone\n\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n\t- Update the configuration file with input/output node names: \tNone\n\t- Use configuration file used to generate the model with Object Detection API: \tNone\n\t- Use the config file: \tNone\n\t- Inference Engine found in: \t/opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/openvino\nInference Engine version: \t2021.4.0-3839-cd81789d294-releases/2021/4\nModel Optimizer version: \t2021.4.0-3839-cd81789d294-releases/2021/4\n/opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  import imp\n[ SUCCESS ] Generated IR version 10 model.\n[ SUCCESS ] XML file: /home/wsuser/work/public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml\n[ SUCCESS ] BIN file: /home/wsuser/work/public/googlenet-v1-tf/FP32/googlenet-v1-tf.bin\n[ SUCCESS ] Total execution time: 35.61 seconds. \n[ SUCCESS ] Memory consumed: 423 MB. \n\n", "name": "stdout"}]}, {"metadata": {"id": "6477f366a16643c2855766615bb88f9b"}, "cell_type": "markdown", "source": "### Benchmark  `googlenet-v1-tf` model with OpenVINO Benchmark App..."}, {"metadata": {"id": "96711ed8d70540618b0ac8af8999b8e3"}, "cell_type": "code", "source": "!benchmark_app -m public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "[Step 1/11] Parsing and validating input arguments\n[ WARNING ]  -nstreams default value is determined automatically for a device. Although the automatic selection usually provides a reasonable performance, but it still may be non-optimal for some cases, for more information look at README. \n[Step 2/11] Loading Inference Engine\n[ INFO ] InferenceEngine:\n         API version............. 2021.4.0-3839-cd81789d294-releases/2021/4\n[ INFO ] Device info\n         CPU\n         MKLDNNPlugin............ version 2.1\n         Build................... 2021.4.0-3839-cd81789d294-releases/2021/4\n\n[Step 3/11] Setting device configuration\n[ WARNING ] -nstreams default value is determined automatically for CPU device. Although the automatic selection usually provides a reasonable performance,but it still may be non-optimal for some cases, for more information look at README.\n[Step 4/11] Reading network files\n[ INFO ] Read network took 50.01 ms\n[Step 5/11] Resizing network to match image sizes and given batch\n[ INFO ] Network batch size: 1\n[Step 6/11] Configuring input of the model\n[ INFO ] Network input 'input' precision U8, dimensions (NCHW): 1 3 224 224\n[ INFO ] Network output 'InceptionV1/Logits/Predictions/Softmax' precision FP32, dimensions (NC): 1 1001\n[Step 7/11] Loading the model to the device\n[ INFO ] Load network took 961.60 ms\n[Step 8/11] Setting optimal runtime parameters\n[Step 9/11] Creating infer requests and filling input blobs with images\n[ WARNING ] No input files were given: all inputs will be filled with random values!\n[ INFO ] Infer Request 0 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 1 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 2 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 3 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 4 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 5 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 6 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 7 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[Step 10/11] Measuring performance (Start inference asynchronously, 8 inference requests using 8 streams for CPU, limits: 60000 ms duration)\n[ INFO ] First inference took 54.05 ms\n[Step 11/11] Dumping statistics report\nCount:      1192 iterations\nDuration:   60490.96 ms\nLatency:    399.41 ms\nThroughput: 19.71 FPS\n", "name": "stdout"}]}, {"metadata": {"id": "123e7b28deba4d8babd79b8766a38091"}, "cell_type": "code", "source": "!ls -la", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "total 20\r\ndrwxr-x---. 3 wsuser  watsonstudio 4096 Jul 14 16:06 .\r\ndrwxrwx---. 1 wsbuild wsbuild      4096 Jul 14 16:06 ..\r\ndrwxr-x---. 3 wsuser  watsonstudio 4096 Jul 14 16:06 public\r\n", "name": "stdout"}]}, {"metadata": {"id": "6580f02f43c0473c96c533dde5e46314"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}