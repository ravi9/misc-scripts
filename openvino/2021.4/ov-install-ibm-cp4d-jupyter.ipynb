{"cells": [{"metadata": {"id": "3a84dd0791f54f2eba25d609d4f4f322"}, "cell_type": "markdown", "source": "# Install OpenVINO in IBM Cloud Pak for Data - Watson Studio Jupyter Env"}, {"metadata": {"id": "7450cea6960b437f8309beea421ddf4b"}, "cell_type": "markdown", "source": "### Use Python 3.6 in IBM CP4D Watson Studio Jupyter Env\n### OpenVINO currently supports Python 3.6, 3.8 on Red Hat* Enterprise Linux* 8, 64-bit\t\n"}, {"metadata": {"id": "26cce525dbbb4c05883ec830764ee424"}, "cell_type": "markdown", "source": "### Sections in the notebook:\n1. Install OpenVINO\n2. Test OpenVINO python imports\n3. Test OpenVINO tools: Model Optimizer, Benchmark App\n4. Sanity check OpenVINO by donwloading, converting and benchmarking googlenet-v1-tf model"}, {"metadata": {"id": "f654368fde164285a10ef2c79811d8cb"}, "cell_type": "markdown", "source": "### Resources:\n1. OpenVINO PyPi: https://pypi.org/project/openvino-dev/\n2. IBM CP4D: [Customizing environment definitions (Watson Studio)](https://www.ibm.com/support/producthub/icpdata/docs/content/SSQNUZ_latest/wsj/analyze-data/cust-env-parent.html)"}, {"metadata": {"id": "0e9acd13bd3d48cd9d6064a4abd30bb8"}, "cell_type": "markdown", "source": "## 1. Install OpenVINO"}, {"metadata": {"id": "7aff8282-127b-43aa-8738-c0096a11e805"}, "cell_type": "code", "source": "# Install this specific version of OpenCV to prevent libGl errors\n!pip uninstall -y opencv-python\n!pip install -U opencv-python-headless==4.2.0.32 --user", "execution_count": null, "outputs": []}, {"metadata": {"id": "ef47c5b9189a4e9a9207d4d88861ce89"}, "cell_type": "code", "source": "# Install OpenVINO\n!pip install --ignore-installed PyYAML openvino-dev", "execution_count": null, "outputs": []}, {"metadata": {"id": "8f19bcb3f1954e1c80746c937f1329fc", "scrolled": true}, "cell_type": "code", "source": "!pip show openvino", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Name: openvino\r\nVersion: 2021.4.0\r\nSummary: Inference Engine Python* API\r\nHome-page: https://docs.openvinotoolkit.org/latest/index.html\r\nAuthor: Intel Corporation\r\nAuthor-email: openvino_pushbot@intel.com\r\nLicense: Proprietary - Intel\r\nLocation: /opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages\r\nRequires: numpy\r\nRequired-by: openvino-dev\r\n", "name": "stdout"}]}, {"metadata": {"id": "05d697550317482189bbcdd29477ecb2"}, "cell_type": "markdown", "source": "### After installing, Restart Kernel just to be sure..."}, {"metadata": {"id": "0bdb111a86d24c9885985ba7d91268d6"}, "cell_type": "markdown", "source": "## 2. Test OpenVINO python imports"}, {"metadata": {"id": "f5ebc3e9eadc40ca8716d1dacc6489c3"}, "cell_type": "code", "source": "from openvino.inference_engine import IENetwork, IECore\nfrom openvino.tools.benchmark.main import main", "execution_count": 4, "outputs": []}, {"metadata": {"id": "aa8d6023fabf490683bf4d75e0c9e74e"}, "cell_type": "markdown", "source": "## 3. Test OpenVINO tools: Model Optimizer, Benchmark App, ..."}, {"metadata": {"id": "cf04e2e81b1049e383b0bb62db50fb79"}, "cell_type": "markdown", "source": "### Test Model Optimizer"}, {"metadata": {"id": "615ca08063454ee59d5d3a0afacf6ac7"}, "cell_type": "code", "source": "!mo --version", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Version of Model Optimizer is: 2021.4.0-3839-cd81789d294-releases/2021/4\r\n", "name": "stdout"}]}, {"metadata": {"id": "71fd9d4272f840d3b41c5c90d20ad4b1"}, "cell_type": "markdown", "source": "### Test Benchmark App"}, {"metadata": {"id": "681bb6c8b36e40b68b05311697cb3d1f"}, "cell_type": "code", "source": "!benchmark_app ", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "[Step 1/11] Parsing and validating input arguments\r\nusage: benchmark_app [-h [HELP]] [-i PATHS_TO_INPUT [PATHS_TO_INPUT ...]] -m\r\n                     PATH_TO_MODEL [-d TARGET_DEVICE] [-l PATH_TO_EXTENSION]\r\n                     [-c PATH_TO_CLDNN_CONFIG] [-api {sync,async}]\r\n                     [-niter NUMBER_ITERATIONS] [-nireq NUMBER_INFER_REQUESTS]\r\n                     [-b BATCH_SIZE] [-stream_output [STREAM_OUTPUT]]\r\n                     [-t TIME] [-progress [PROGRESS]] [-shape SHAPE]\r\n                     [-layout LAYOUT] [-nstreams NUMBER_STREAMS]\r\n                     [-enforcebf16 [{True,False}]] [-nthreads NUMBER_THREADS]\r\n                     [-pin {YES,NO,NUMA,HYBRID_AWARE}]\r\n                     [-exec_graph_path EXEC_GRAPH_PATH] [-pc [PERF_COUNTS]]\r\n                     [-report_type {no_counters,average_counters,detailed_counters}]\r\n                     [-report_folder REPORT_FOLDER] [-dump_config DUMP_CONFIG]\r\n                     [-load_config LOAD_CONFIG] [-qb {8,16}]\r\n                     [-ip {U8,FP16,FP32}] [-op {U8,FP16,FP32}]\r\n                     [-iop INPUT_OUTPUT_PRECISION] [-cdir CACHE_DIR]\r\n                     [-lfile [LOAD_FROM_FILE]]\r\nbenchmark_app: error: the following arguments are required: -m/--path_to_model\r\n", "name": "stdout"}]}, {"metadata": {"id": "aea7148993b54701844377a75ef2af66"}, "cell_type": "markdown", "source": "### See other tools:"}, {"metadata": {"id": "4c62e4c8a0d84964ba3aaae8ea9fccc3"}, "cell_type": "code", "source": "!ls /opt/conda/envs/Python-3.6-WMLCE/bin/omz*", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "/opt/conda/envs/Python-3.6-WMLCE/bin/omz_converter\r\n/opt/conda/envs/Python-3.6-WMLCE/bin/omz_downloader\r\n/opt/conda/envs/Python-3.6-WMLCE/bin/omz_info_dumper\r\n/opt/conda/envs/Python-3.6-WMLCE/bin/omz_quantizer\r\n", "name": "stdout"}]}, {"metadata": {"id": "911bad7f35bb40978017463432b088f8"}, "cell_type": "markdown", "source": "## 4. Sanity check OpenVINO by donwloading, converting and benchmarking googlenet-v1-tf model\n"}, {"metadata": {"id": "3015d3c1b6da4e4ba6e1084701a2108b"}, "cell_type": "markdown", "source": "### Resources:\n\n1. OpenVINO Model Zoo (OMZ): https://github.com/openvinotoolkit/open_model_zoo\n1. OMZ Intel Pre-Trained Models : https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/index.md\n1. OMZ Public Pre-Trained Models: See Column 3 for OMZ model name: https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/index.md"}, {"metadata": {"id": "f8c88985ca16414082ec60115a4f754a"}, "cell_type": "markdown", "source": "### Download  `googlenet-v1-tf` model from OMZ"}, {"metadata": {"id": "bb14aaa7793b413383142b1bc383e91c", "scrolled": true}, "cell_type": "code", "source": "!omz_downloader --name googlenet-v1-tf", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "################|| Downloading googlenet-v1-tf ||################\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/inception_v1_2016_08_28.tar.gz\n... 100%, 24064 KB, 49851 KB/s, 0 seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/inception.py\n... 100%, 1 KB, 4530 KB/s, 0 seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/inception_utils.py\n... 100%, 3 KB, 11466 KB/s, 0 seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/inception_v1.py\n... 100%, 16 KB, 44717 KB/s, 0 seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/nets_factory.py\n... 100%, 7 KB, 24174 KB/s, 0 seconds passed\n\n========== Downloading /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/tf_slim-1.1.0-py2.py3-none-any.whl\n... 100%, 343 KB, 19899 KB/s, 0 seconds passed\n\n========== Unpacking /home/wsuser/work/public/googlenet-v1-tf/inception_v1_2016_08_28.tar.gz\n========== Unpacking /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/tf_slim-1.1.0-py2.py3-none-any.whl\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/nets_factory.py\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/nets_factory.py\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/inception.py\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/nets/nets_factory.py\n========== Replacing text in /home/wsuser/work/public/googlenet-v1-tf/models/research/slim/tf_slim/layers/layers.py\n\n", "name": "stdout"}]}, {"metadata": {"id": "0f9c1cb31a874f8db5d37b550d5b45d3"}, "cell_type": "markdown", "source": "!ls public/googlenet-v1-tf/"}, {"metadata": {"id": "97f8ea53e843446c83f45c797a04c50f"}, "cell_type": "markdown", "source": "### Convert `googlenet-v1-tf` model to OpenVINO IR"}, {"metadata": {"id": "fe5f01a0bdd147e087f26ed5f9858755"}, "cell_type": "code", "source": "!omz_converter --name googlenet-v1-tf", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "========== Running pre-convert script for googlenet-v1-tf\nPre-convert command: /opt/conda/envs/Python-3.6-WMLCE/bin/python -- /opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/open_model_zoo/model_tools/models/public/googlenet-v1-tf/pre-convert.py -- /home/wsuser/work/public/googlenet-v1-tf /home/wsuser/work/public/googlenet-v1-tf\n\n2021-07-13 21:11:13.180277: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2021-07-13 21:11:13.191196: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 2100030000 Hz\n2021-07-13 21:11:13.194739: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e1cb7191f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2021-07-13 21:11:13.194805: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\nWARNING: Logging before flag parsing goes to stderr.\nW0713 21:11:16.353588 140285484640064 deprecation.py:323] From /opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/open_model_zoo/model_tools/models/public/googlenet-v1-tf/pre-convert.py:45: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\nW0713 21:11:16.354113 140285484640064 deprecation.py:323] From /opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.extract_sub_graph`\n\n========== Converting googlenet-v1-tf to IR (FP16)\nConversion command: /opt/conda/envs/Python-3.6-WMLCE/bin/python -m mo --framework=tf --data_type=FP16 --output_dir=/home/wsuser/work/public/googlenet-v1-tf/FP16 --model_name=googlenet-v1-tf '--input_shape=[1,224,224,3]' --input=input '--mean_values=input[127.5,127.5,127.5]' '--scale_values=input[127.5]' --output=InceptionV1/Logits/Predictions/Softmax --input_model=/home/wsuser/work/public/googlenet-v1-tf/inception_v1.frozen.pb --reverse_input_channels\n\nModel Optimizer arguments:\nCommon parameters:\n\t- Path to the Input Model: \t/home/wsuser/work/public/googlenet-v1-tf/inception_v1.frozen.pb\n\t- Path for generated IR: \t/home/wsuser/work/public/googlenet-v1-tf/FP16\n\t- IR output name: \tgooglenet-v1-tf\n\t- Log level: \tERROR\n\t- Batch: \tNot specified, inherited from the model\n\t- Input layers: \tinput\n\t- Output layers: \tInceptionV1/Logits/Predictions/Softmax\n\t- Input shapes: \t[1,224,224,3]\n\t- Mean values: \tinput[127.5,127.5,127.5]\n\t- Scale values: \tinput[127.5]\n\t- Scale factor: \tNot specified\n\t- Precision of IR: \tFP16\n\t- Enable fusing: \tTrue\n\t- Enable grouped convolutions fusing: \tTrue\n\t- Move mean values to preprocess section: \tNone\n\t- Reverse input channels: \tTrue\nTensorFlow specific parameters:\n\t- Input model in text protobuf format: \tFalse\n\t- Path to model dump for TensorBoard: \tNone\n\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n\t- Update the configuration file with input/output node names: \tNone\n\t- Use configuration file used to generate the model with Object Detection API: \tNone\n\t- Use the config file: \tNone\n\t- Inference Engine found in: \t/opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/openvino\nInference Engine version: \t2021.4.0-3839-cd81789d294-releases/2021/4\nModel Optimizer version: \t2021.4.0-3839-cd81789d294-releases/2021/4\n/opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  import imp\n[ SUCCESS ] Generated IR version 10 model.\n[ SUCCESS ] XML file: /home/wsuser/work/public/googlenet-v1-tf/FP16/googlenet-v1-tf.xml\n[ SUCCESS ] BIN file: /home/wsuser/work/public/googlenet-v1-tf/FP16/googlenet-v1-tf.bin\n[ SUCCESS ] Total execution time: 35.88 seconds. \n[ SUCCESS ] Memory consumed: 421 MB. \n\n========== Converting googlenet-v1-tf to IR (FP32)\nConversion command: /opt/conda/envs/Python-3.6-WMLCE/bin/python -m mo --framework=tf --data_type=FP32 --output_dir=/home/wsuser/work/public/googlenet-v1-tf/FP32 --model_name=googlenet-v1-tf '--input_shape=[1,224,224,3]' --input=input '--mean_values=input[127.5,127.5,127.5]' '--scale_values=input[127.5]' --output=InceptionV1/Logits/Predictions/Softmax --input_model=/home/wsuser/work/public/googlenet-v1-tf/inception_v1.frozen.pb --reverse_input_channels\n\nModel Optimizer arguments:\nCommon parameters:\n\t- Path to the Input Model: \t/home/wsuser/work/public/googlenet-v1-tf/inception_v1.frozen.pb\n\t- Path for generated IR: \t/home/wsuser/work/public/googlenet-v1-tf/FP32\n\t- IR output name: \tgooglenet-v1-tf\n\t- Log level: \tERROR\n\t- Batch: \tNot specified, inherited from the model\n\t- Input layers: \tinput\n\t- Output layers: \tInceptionV1/Logits/Predictions/Softmax\n\t- Input shapes: \t[1,224,224,3]\n\t- Mean values: \tinput[127.5,127.5,127.5]\n\t- Scale values: \tinput[127.5]\n\t- Scale factor: \tNot specified\n\t- Precision of IR: \tFP32\n\t- Enable fusing: \tTrue\n\t- Enable grouped convolutions fusing: \tTrue\n\t- Move mean values to preprocess section: \tNone\n\t- Reverse input channels: \tTrue\nTensorFlow specific parameters:\n\t- Input model in text protobuf format: \tFalse\n\t- Path to model dump for TensorBoard: \tNone\n\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n\t- Update the configuration file with input/output node names: \tNone\n\t- Use configuration file used to generate the model with Object Detection API: \tNone\n\t- Use the config file: \tNone\n\t- Inference Engine found in: \t/opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/openvino\nInference Engine version: \t2021.4.0-3839-cd81789d294-releases/2021/4\nModel Optimizer version: \t2021.4.0-3839-cd81789d294-releases/2021/4\n/opt/conda/envs/Python-3.6-WMLCE/lib/python3.6/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  import imp\n[ SUCCESS ] Generated IR version 10 model.\n[ SUCCESS ] XML file: /home/wsuser/work/public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml\n[ SUCCESS ] BIN file: /home/wsuser/work/public/googlenet-v1-tf/FP32/googlenet-v1-tf.bin\n[ SUCCESS ] Total execution time: 35.69 seconds. \n[ SUCCESS ] Memory consumed: 422 MB. \n\n", "name": "stdout"}]}, {"metadata": {"id": "6477f366a16643c2855766615bb88f9b"}, "cell_type": "markdown", "source": "### Benchmark  `googlenet-v1-tf` model with OpenVINO Benchmark App..."}, {"metadata": {"id": "96711ed8d70540618b0ac8af8999b8e3"}, "cell_type": "code", "source": "!benchmark_app -m public/googlenet-v1-tf/FP32/googlenet-v1-tf.xml", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "[Step 1/11] Parsing and validating input arguments\n[ WARNING ]  -nstreams default value is determined automatically for a device. Although the automatic selection usually provides a reasonable performance, but it still may be non-optimal for some cases, for more information look at README. \n[Step 2/11] Loading Inference Engine\n[ INFO ] InferenceEngine:\n         API version............. 2021.4.0-3839-cd81789d294-releases/2021/4\n[ INFO ] Device info\n         CPU\n         MKLDNNPlugin............ version 2.1\n         Build................... 2021.4.0-3839-cd81789d294-releases/2021/4\n\n[Step 3/11] Setting device configuration\n[ WARNING ] -nstreams default value is determined automatically for CPU device. Although the automatic selection usually provides a reasonable performance,but it still may be non-optimal for some cases, for more information look at README.\n[Step 4/11] Reading network files\n[ INFO ] Read network took 51.20 ms\n[Step 5/11] Resizing network to match image sizes and given batch\n[ INFO ] Network batch size: 1\n[Step 6/11] Configuring input of the model\n[ INFO ] Network input 'input' precision U8, dimensions (NCHW): 1 3 224 224\n[ INFO ] Network output 'InceptionV1/Logits/Predictions/Softmax' precision FP32, dimensions (NC): 1 1001\n[Step 7/11] Loading the model to the device\n[ INFO ] Load network took 950.53 ms\n[Step 8/11] Setting optimal runtime parameters\n[Step 9/11] Creating infer requests and filling input blobs with images\n[ WARNING ] No input files were given: all inputs will be filled with random values!\n[ INFO ] Infer Request 0 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 1 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 2 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 3 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 4 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 5 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 6 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[ INFO ] Infer Request 7 filling\n[ INFO ] Fill input 'input' with random values (image is expected)\n[Step 10/11] Measuring performance (Start inference asynchronously, 8 inference requests using 8 streams for CPU, limits: 60000 ms duration)\n[ INFO ] First inference took 52.18 ms\n[Step 11/11] Dumping statistics report\nCount:      1192 iterations\nDuration:   60386.60 ms\nLatency:    399.29 ms\nThroughput: 19.74 FPS\n", "name": "stdout"}]}, {"metadata": {"id": "123e7b28deba4d8babd79b8766a38091"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}